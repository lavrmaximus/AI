import g4f
import re
import logging
from typing import Dict, List, Tuple
from database import db

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

g4f.debug.logging = False

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å (—Ç–µ–ø–µ—Ä—å –¥—É–±–ª–∏—Ä—É–µ—Ç—Å—è –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö)
conversation_memory = {}

# –£–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
MESSAGE_CLASSIFIER_PROMPT = """–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏ –µ–≥–æ —Ç–∏–ø:

1. BUSINESS_ANALYSIS - –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ–ø–∏—Å—ã–≤–∞–µ—Ç –±–∏–∑–Ω–µ—Å —Å —Ü–∏—Ñ—Ä–∞–º–∏ (–≤—ã—Ä—É—á–∫–∞, —Ä–∞—Å—Ö–æ–¥—ã, –∫–ª–∏–µ–Ω—Ç—ã, –ø—Ä–∏–±—ã–ª—å –∏ —Ç.–¥.)
2. BUSINESS_QUESTION - –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –æ –±–∏–∑–Ω–µ—Å–µ, —Ñ–∏–Ω–∞–Ω—Å–∞—Ö, –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å—Ç–≤–µ
3. GENERAL_CHAT - –µ—Å–ª–∏ —ç—Ç–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –æ–±—â–µ–Ω–∏–µ –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ —Å–≤—è–∑–∞–Ω–æ —Å –±–∏–∑–Ω–µ—Å–æ–º

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: BUSINESS_ANALYSIS, BUSINESS_QUESTION –∏–ª–∏ GENERAL_CHAT.

–ü—Ä–∏–º–µ—Ä—ã:
- "–í—ã—Ä—É—á–∫–∞ 500–∫, —Ä–∞—Å—Ö–æ–¥—ã 200–∫" -> BUSINESS_ANALYSIS
- "–ö–∞–∫ —É–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–∏–±—ã–ª—å?" -> BUSINESS_QUESTION  
- "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?" -> GENERAL_CHAT
- "–°–ø–∞—Å–∏–±–æ –∑–∞ –ø–æ–º–æ—â—å" -> GENERAL_CHAT"""

BUSINESS_ANALYSIS_PROMPT = """–¢—ã - –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ - –ò–ó–í–õ–ï–ß–¨ –¶–ò–§–†–´ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏ –¥–∞—Ç—å –∫—Ä–∞—Ç–∫–∏–π –∞–Ω–∞–ª–∏–∑.

–û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤ —ç—Ç–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –ë–ï–ó –õ–ò–®–ù–ò–• –°–õ–û–í:

–í–´–†–£–ß–ö–ê: 45000000
–†–ê–°–•–û–î–´: 38000000
–ü–†–ò–ë–´–õ–¨: 7000000
–ö–õ–ò–ï–ù–¢–´: 15
–°–†–ï–î–ù–ò–ô_–ß–ï–ö: 3000000
–ò–ù–í–ï–°–¢–ò–¶–ò–ò: 10000000
–û–¶–ï–ù–ö–ê: 8
–ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô: –í–∞—à –±–∏–∑–Ω–µ—Å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç —Ö–æ—Ä–æ—à—É—é —Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å. –†–µ–∫–æ–º–µ–Ω–¥—É—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å—Ö–æ–¥—ã.
–°–û–í–ï–¢–´: 1. –°–Ω–∏–∑–∏—Ç—å –æ–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ä–∞—Å—Ö–æ–¥—ã|2. –£–≤–µ–ª–∏—á–∏—Ç—å —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫|3. –ü—Ä–∏–≤–ª–µ—á—å –±–æ–ª—å—à–µ –∫–ª–∏–µ–Ω—Ç–æ–≤

–ï—Å–ª–∏ —Ü–∏—Ñ—Ä—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã - —Å—Ç–∞–≤—å 0.
–ù–ò–ö–ê–ö–ò–• –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –∫—Ä–æ–º–µ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö –ø–æ–ª–µ–π."""

QUESTION_ANSWER_PROMPT = """–¢—ã - –æ–ø—ã—Ç–Ω—ã–π –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Å 10-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º. –û—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –∫–µ–π—Å—ã –∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã. –ë—É–¥—å –ø–æ–ª–µ–∑–Ω—ã–º –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∏–º."""

GENERAL_CHAT_PROMPT = """–¢—ã - –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª–µ–π. –ü–æ–¥–¥–µ—Ä–∂–∏ –±–µ—Å–µ–¥—É, –±—É–¥—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º. –ú—è–≥–∫–æ –Ω–∞–ø—Ä–∞–≤–ª—è–π —Ä–∞–∑–≥–æ–≤–æ—Ä –≤ —Å—Ç–æ—Ä–æ–Ω—É –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏–∑–∞, –µ—Å–ª–∏ —ç—Ç–æ —É–º–µ—Å—Ç–Ω–æ."""

async def classify_message_type(text: str) -> str:
    """–£–º–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –ø–æ–º–æ—â—å—é AI"""
    try:
        messages = [
            {"role": "system", "content": MESSAGE_CLASSIFIER_PROMPT},
            {"role": "user", "content": text}
        ]
        
        response = g4f.ChatCompletion.create(
            model=g4f.models.gpt_4,
            messages=messages,
            stream=False
        )
        
        response = response.strip().upper()
        
        if "BUSINESS_ANALYSIS" in response:
            return "business_analysis"
        elif "BUSINESS_QUESTION" in response:
            return "question"
        else:
            return "general"
            
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        return simple_detect_message_type(text)

def simple_detect_message_type(text: str) -> str:
    """–ü—Ä–æ—Å—Ç–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å–æ–æ–±—â–µ–Ω–∏—è (fallback)"""
    text_lower = text.lower()
    
    # –ë–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏—Ç–∏–∫–∞ (—Ü–∏—Ñ—Ä—ã + –±–∏–∑–Ω–µ—Å-—Å–ª–æ–≤–∞)
    business_words = ['–≤—ã—Ä—É—á–∫–∞', '–¥–æ—Ö–æ–¥', '–ø—Ä–∏–±—ã–ª—å', '—Ä–∞—Å—Ö–æ–¥', '–∑–∞—Ç—Ä–∞—Ç', '–∫–ª–∏–µ–Ω—Ç', '–ø—Ä–æ–¥–∞–∂', 
                     '–∑–∞–∫–∞–∑', '—á–µ–∫', '–∏–Ω–≤–µ—Å—Ç–∏—Ü', '—Ä–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å', '–æ–±–æ—Ä–æ—Ç', '–∞–∫—Ç–∏–≤', '–∫–∞–ø–∏—Ç–∞–ª',
                     '–±–∏–∑–Ω–µ—Å', '–∫–æ–º–ø–∞–Ω–∏—è', '–ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ', '–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å']
    has_numbers = bool(re.search(r'\d', text))
    has_business_words = any(word in text_lower for word in business_words)
    
    if has_numbers and has_business_words:
        return "business_analysis"
    
    # –í–æ–ø—Ä–æ—Å—ã
    question_words = ['–∫–∞–∫', '—á—Ç–æ', '–ø–æ—á–µ–º—É', '–∑–∞—á–µ–º', '–∫–æ–≥–¥–∞', '–≥–¥–µ', '–∫—Ç–æ', '—á–µ–º', '?']
    business_questions = ['—É–≤–µ–ª–∏—á', '—É–ª—É—á—à', '–æ–ø—Ç–∏–º–∏–∑', '—Ä–∞–∑–≤–∏—Ç', '–ø—Ä–æ–±–ª–µ–º', '—Å–æ–≤–µ—Ç', '—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü']
    
    is_question = any(word in text_lower for word in question_words)
    is_business_question = any(word in text_lower for word in business_questions)
    
    if is_question and is_business_question:
        return "question"
    
    # –û–±—â–∏–π —á–∞—Ç
    return "general"

async def analyze_business(description: str, user_id: str = "default") -> Dict:
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –±–∏–∑–Ω–µ—Å–∞ —Å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
    
    if user_id not in conversation_memory:
        conversation_memory[user_id] = [
            {"role": "system", "content": BUSINESS_ANALYSIS_PROMPT}
        ]
    
    messages = conversation_memory[user_id]
    messages.append({"role": "user", "content": description})
    
    try:
        response = g4f.ChatCompletion.create(
            model=g4f.models.gpt_4,
            messages=messages,
            stream=False
        )
        
        messages.append({"role": "assistant", "content": response})
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        if len(messages) > 12:
            conversation_memory[user_id] = [messages[0]] + messages[-10:]
        
        parsed_data = parse_business_response(response)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        await db.save_business_analysis(user_id, parsed_data)
        
        return parsed_data
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏–∑–∞: {e}")
        return {"error": str(e), "type": "business_analysis"}

async def answer_question(question: str, user_id: str = "default") -> str:
    """–û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –æ –±–∏–∑–Ω–µ—Å–µ"""
    
    if user_id not in conversation_memory:
        conversation_memory[user_id] = [
            {"role": "system", "content": QUESTION_ANSWER_PROMPT}
        ]
    
    messages = conversation_memory[user_id]
    messages.append({"role": "user", "content": question})
    
    try:
        response = g4f.ChatCompletion.create(
            model=g4f.models.gpt_4,
            messages=messages,
            stream=False
        )
        
        messages.append({"role": "assistant", "content": response})
        
        if len(messages) > 12:
            conversation_memory[user_id] = [messages[0]] + messages[-10:]
        
        return response
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å: {e}")
        return f"–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}"

async def general_chat(message: str, user_id: str = "default") -> str:
    """–û–±—â–∏–π —Ä–∞–∑–≥–æ–≤–æ—Ä"""
    
    if user_id not in conversation_memory:
        conversation_memory[user_id] = [
            {"role": "system", "content": GENERAL_CHAT_PROMPT}
        ]
    
    messages = conversation_memory[user_id]
    messages.append({"role": "user", "content": message})
    
    try:
        response = g4f.ChatCompletion.create(
            model=g4f.models.gpt_4,
            messages=messages,
            stream=False
        )
        
        messages.append({"role": "assistant", "content": response})
        
        if len(messages) > 10:
            conversation_memory[user_id] = [messages[0]] + messages[-8:]
        
        return response
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—â–µ–≥–æ —á–∞—Ç–∞: {e}")
        return "–ü—Ä–∏–≤–µ—Ç! –†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ —Å–≤–æ–µ–º –±–∏–∑–Ω–µ—Å–µ - –ø–æ–º–æ–≥—É —Å –∞–Ω–∞–ª–∏–∑–æ–º!"

def parse_business_response(text: str) -> Dict:
    """–ü–∞—Ä—Å–∏–º —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏–∑"""
    
    data = {
        "–í–´–†–£–ß–ö–ê": 0, "–†–ê–°–•–û–î–´": 0, "–ü–†–ò–ë–´–õ–¨": 0, 
        "–ö–õ–ò–ï–ù–¢–´": 0, "–°–†–ï–î–ù–ò–ô_–ß–ï–ö": 0, "–ò–ù–í–ï–°–¢–ò–¶–ò–ò": 0,
        "–û–¶–ï–ù–ö–ê": 0, "–†–û–ï–ù–¢–ê–ë–ï–õ–¨–ù–û–°–¢–¨": 0, "–¢–û–ß–ö–ê_–ë–ï–ó–£–ë–´–¢–û–ß–ù–û–°–¢–ò": 0,
        "–ó–ê–ü–ê–°_–ü–†–û–ß–ù–û–°–¢–ò": 0, "–ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô": "", "–°–û–í–ï–¢–´": [],
        "type": "business_analysis"
    }
    
    # –ü–∞—Ä—Å–∏–º –±–∞–∑–æ–≤—ã–µ —Ü–∏—Ñ—Ä—ã
    lines = text.split('\n')
    for line in lines:
        line = line.strip()
        for key in data:
            if line.startswith(key + ":"):
                numbers = re.findall(r'\d+\.?\d*', line)
                if numbers:
                    data[key] = float(numbers[0])
    
    # –ü–∞—Ä—Å–∏–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –∏ —Å–æ–≤–µ—Ç—ã
    if "–ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô:" in text:
        comment_part = text.split("–ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô:")[1]
        if "–°–û–í–ï–¢–´:" in comment_part:
            data["–ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô"] = comment_part.split("–°–û–í–ï–¢–´:")[0].strip()
        else:
            data["–ö–û–ú–ú–ï–ù–¢–ê–†–ò–ô"] = comment_part.strip()
    
    if "–°–û–í–ï–¢–´:" in text:
        advice_part = text.split("–°–û–í–ï–¢–´:")[1]
        advice_lines = [line.strip() for line in advice_part.split('\n') if line.strip()]
        for line in advice_lines:
            # –£–±–∏—Ä–∞–µ–º –Ω—É–º–µ—Ä–∞—Ü–∏—é (1., 2., –∏ —Ç.–¥.)
            clean_advice = re.sub(r'^\d+\.\s*', '', line).strip()
            if clean_advice and '|' in clean_advice:
                # –†–∞–∑–¥–µ–ª—è–µ–º —Å–æ–≤–µ—Ç—ã –ø–æ |
                data["–°–û–í–ï–¢–´"].extend([a.strip() for a in clean_advice.split('|') if a.strip()])
            elif clean_advice:
                data["–°–û–í–ï–¢–´"].append(clean_advice)
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–≤–µ—Ç–æ–≤
    data["–°–û–í–ï–¢–´"] = data["–°–û–í–ï–¢–´"][:3]
    
    return data

def calculate_advanced_metrics(business_data: Dict) -> Dict:
    """–†–∞—Å—á–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫"""
    
    metrics = {}
    
    try:
        # 1. –†–µ–Ω—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å –ø—Ä–æ–¥–∞–∂
        if business_data["–í–´–†–£–ß–ö–ê"] > 0:
            metrics["–†–û–ï–ù–¢–ê–ë–ï–õ–¨–ù–û–°–¢–¨"] = (business_data["–ü–†–ò–ë–´–õ–¨"] / business_data["–í–´–†–£–ß–ö–ê"]) * 100
        
        # 2. –¢–æ—á–∫–∞ –±–µ–∑—É–±—ã—Ç–æ—á–Ω–æ—Å—Ç–∏ (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
        if business_data["–°–†–ï–î–ù–ò–ô_–ß–ï–ö"] > 0 and business_data["–†–ê–°–•–û–î–´"] > 0:
            metrics["–¢–û–ß–ö–ê_–ë–ï–ó–£–ë–´–¢–û–ß–ù–û–°–¢–ò"] = business_data["–†–ê–°–•–û–î–´"] / business_data["–°–†–ï–î–ù–ò–ô_–ß–ï–ö"]
        
        # 3. –ó–∞–ø–∞—Å —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –ø—Ä–æ—á–Ω–æ—Å—Ç–∏
        if business_data["–í–´–†–£–ß–ö–ê"] > 0 and metrics.get("–¢–û–ß–ö–ê_–ë–ï–ó–£–ë–´–¢–û–ß–ù–û–°–¢–ò", 0) > 0:
            break_even_revenue = metrics["–¢–û–ß–ö–ê_–ë–ï–ó–£–ë–´–¢–û–ß–ù–û–°–¢–ò"] * business_data["–°–†–ï–î–ù–ò–ô_–ß–ï–ö"]
            if break_even_revenue > 0:
                metrics["–ó–ê–ü–ê–°_–ü–†–û–ß–ù–û–°–¢–ò"] = ((business_data["–í–´–†–£–ß–ö–ê"] - break_even_revenue) / business_data["–í–´–†–£–ß–ö–ê"]) * 100
        
        # 6. –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç —É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç–∏ —Ä–æ—Å—Ç–∞ (SGR)
        if business_data["–ü–†–ò–ë–´–õ–¨"] > 0 and business_data["–ò–ù–í–ï–°–¢–ò–¶–ò–ò"] > 0:
            roe = (business_data["–ü–†–ò–ë–´–õ–¨"] / business_data["–ò–ù–í–ï–°–¢–ò–¶–ò–ò"]) * 100
            metrics["SGR"] = roe * 0.5  # 50% —Ä–µ–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π
        
        # 7. –ò–Ω–¥–µ–∫—Å –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç–∏ (PI)
        if business_data["–ò–ù–í–ï–°–¢–ò–¶–ò–ò"] > 0:
            annual_profit = business_data["–ü–†–ò–ë–´–õ–¨"] * 12
            metrics["–ò–ù–î–ï–ö–°_–ü–†–ò–ë–´–õ–¨–ù–û–°–¢–ò"] = annual_profit / business_data["–ò–ù–í–ï–°–¢–ò–¶–ò–ò"]
        
        return metrics
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫: {e}")
        return {}

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
if __name__ == "__main__":
    import asyncio
    
    async def test_ai():
        print("üß† –¢–µ—Å—Ç–∏—Ä—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π AI...")
        
        # –¢–µ—Å—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        test_messages = [
            "–í—ã—Ä—É—á–∫–∞ 500–∫ –≤ –º–µ—Å—è—Ü, —Ä–∞—Å—Ö–æ–¥—ã 200–∫",
            "–ö–∞–∫ —É–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–∏–±—ã–ª—å?",
            "–ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –¥–µ–ª–∞?",
            "–£ –º–µ–Ω—è –∫–æ—Ñ–µ–π–Ω—è, 30 –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –¥–µ–Ω—å, —Å—Ä–µ–¥–Ω–∏–π —á–µ–∫ 500 —Ä—É–±–ª–µ–π"
        ]
        
        for msg in test_messages:
            msg_type = await classify_message_type(msg)
            print(f"–°–æ–æ–±—â–µ–Ω–∏–µ: '{msg}' -> –¢–∏–ø: {msg_type}")
        
        # –¢–µ—Å—Ç –±–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏–∑–∞
        test_business = "–ö–æ—Ñ–µ–π–Ω—è: –≤—ã—Ä—É—á–∫–∞ 500000 –≤ –º–µ—Å—è—Ü, 30 –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ –¥–µ–Ω—å, —Ä–∞—Å—Ö–æ–¥—ã 200000, –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏ 1000000"
        result = await analyze_business(test_business)
        print("–ë–∏–∑–Ω–µ—Å-–∞–Ω–∞–ª–∏–∑:", result)
        
        # –¢–µ—Å—Ç –≤–æ–ø—Ä–æ—Å–∞
        test_question = "–ö–∞–∫ —É–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–∏–±—ã–ª—å –≤ —Ä–æ–∑–Ω–∏—á–Ω–æ–º –º–∞–≥–∞–∑–∏–Ω–µ?"
        result = await answer_question(test_question)
        print("–û—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å:", result[:100] + "...")
    
    asyncio.run(test_ai())